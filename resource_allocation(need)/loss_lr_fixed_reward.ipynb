{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"loss_lr_fixed_reward.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"1r6HruNZmw58"},"source":["### iid"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tOkxrAqDYnlB","executionInfo":{"status":"ok","timestamp":1626964145881,"user_tz":-480,"elapsed":27940,"user":{"displayName":"张家祥","photoUrl":"","userId":"07734819762891829185"}},"outputId":"5d4db527-ce08-43c6-a7b3-e36706fae709"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ielVYhbNm7Qq"},"source":["### 准备各个用户数据"]},{"cell_type":"code","metadata":{"id":"Q1CZY2yBIsaL"},"source":["%tensorflow_version 1.x\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import random\n","import math\n","\n","# 准备各个用户数据\n","from tensorflow.examples.tutorials.mnist import input_data \n","mnist=input_data.read_data_sets('MNIST data',one_hot=True)\n","datas=mnist.train.images\n","labels=mnist.train.labels\n","\n","bs_number=4\n","good_user_number=10\n","\n","\n","all_user_data=[]\n","all_user_label=[]\n","\n","for i in range(good_user_number):\n","  all_user_data.append(datas[i*4000:(i+1)*4000,])\n","  all_user_label.append(labels[i*4000:(i+1)*4000,])\n","\n","test_data=mnist.test.images[:100]\n","test_label=mnist.test.labels[:100]\n","\n","\n","channel_number = 20\n","\n","channel_state = [[0.6,0.3,0.1], [0.3,0.1,0.6], [0.1,0.6,0.3]]  # Transition probability of computation capbility: bad, Medium, Good\n","snr = np.array([1, 7, 15])\n","bandwidth = 20 * 10**6  # 2MHz\n","\n","computation_state = [[0.7,0.2,0.1],[0.2,0.1,0.7],[0.1,0.7,0.2]]\n","# computation_state = [[0.5,0.3,0.2],[0.3,0.5,0.2],[0.2,0.3,0.5]]\n","bs_comp_capacity = np.array([20, 60, 100]) #GHz\n","user_comp_capacity = np.array([1, 3, 5])  #GHz\n","\n","\n","alpha = 0.01 #G cycles to generate or verify a signature\n","beta = 0.0001 #G cycles to generate or verify a MAC\n","time_to_fl_limit=60\n","time_to_bc_limit=18\n","epsilon=10**(-28)\n","omega=10**6*8 #1Mb\n","theta_1=0.01 #G cycles\n","theta_2=0.0001  #G cycles\n","theta_3=0.005  #G cycles\n","power_b=16 #W 42dbm\n","power_u=0.5 #W 27dbm\n","user_data_size=4000 #sample\n","\n","\n","block_size_space = np.array([1 * (10**6), 2 * (10**6), 5 * (10**6), 11* (10**6)]) # blcok size 取 {1,2,5,11}M, 此处单位是Byte\n","block_producer_space = np.array([1,2,3,4]) #产生区块的节点\n","faulty_nodes = math.ceil((bs_number - 1)/3) #向上取整\n","\n","# action格式:给用户和基站分配信道数，第一个数表示多余的信道分给谁，取值范围小于用户数加基站数（基站+用户），最后两个优化block size和产生区块的主节点\n","extra_channel = 1 \n","action = np.array([1] + [1] + [1])  \n","\n","\n","def reset(user_number):\n","\n","  channel_space = np.arange(1, user_number + bs_number + 1)\n","\n","\n","  # state格式:用户与基站间SNR，基站与基站之间的SNR，基站和用户的计算能力,当前的委员会节点\n","  state = np.array([1] * user_number * bs_number + [1] * bs_number * user_number+ [1] * bs_number * bs_number + [1] * (bs_number + user_number) + [1] * user_number)\n","  n_features = len(state)\n","\n","  action_space_size = len(block_size_space)*len(block_producer_space)*(len(channel_space)**(extra_channel))\n","\n","  actionRangeMatrix = [channel_space for i in range(extra_channel)]\n","  actionRangeMatrix.append(block_size_space)  # 倒数第二维的取值范围\n","  actionRangeMatrix.append(block_producer_space)  # 倒数第一维的取值范围\n","\n","  reseted_state=[]\n","  for i in range(2*user_number*bs_number+bs_number*bs_number):\n","    reseted_state.append(snr[i%3])\n","  reseted_state+=[20,60,100,100]\n","  for i in range(user_number):\n","    reseted_state.append(user_comp_capacity[i%3])\n","  reseted_state+=[1 for i in range(user_number)]\n","\n","  n_actions = len(block_size_space)*len(block_producer_space)*len(channel_space)**(extra_channel)\n","\n","  return n_features,n_actions,np.array(reseted_state),actionRangeMatrix\n","\n","\n","      \n","\n","\n","def theNiubiFunction(index):\n","    theResultIndexOfAixs = [0] * (extra_channel + 2)\n","    currentAixs = len(actionRangeMatrix) - 1\n","    while index > 0:\n","        currentAixsLength = len(actionRangeMatrix[currentAixs])\n","        theResultIndexOfAixs[currentAixs] = index % currentAixsLength\n","        index = int(index / currentAixsLength)\n","        currentAixs = currentAixs - 1\n","\n","    return [actionRangeMatrix[x][theResultIndexOfAixs[x]] for x in range(extra_channel + 2)] \n","\n","\n","# module = 0 表示对三者都优化; module = 1，表示信道分配固定；module = 2，表示block_size固定；module = 3，表示block_producer固定。\n","def move(state,action,module=0):  \n","    state_copy=state.copy()\n","    user_bs_snr_status = state_copy[:user_number * bs_number]\n","    user_bs_snr_status = np.reshape(user_bs_snr_status, (user_number, bs_number))  #user_number行，bs_number列\n","  \n","    bs_user_snr_status = state_copy[user_number * bs_number:user_number*bs_number+bs_number*user_number]\n","    bs_user_snr_status = np.reshape(bs_user_snr_status, (bs_number ,user_number))\n","    \n","    bs_snr_status = state_copy[user_number * bs_number+bs_number*user_number:user_number * bs_number +bs_number*user_number+ bs_number * bs_number]\n","    bs_snr_status = np.reshape(bs_snr_status, (bs_number, bs_number))\n","    \n","    bs_comp_status = state_copy[user_number * bs_number +bs_number*user_number+ bs_number * bs_number:user_number * bs_number +bs_number*user_number+ bs_number * bs_number + bs_number]\n","\n","    user_comp_status = state_copy[user_number * bs_number +bs_number*user_number+ bs_number * bs_number + bs_number:user_number * bs_number +bs_number*user_number+ bs_number * bs_number + bs_number + user_number]\n","\n","    user_committee_status = state_copy[user_number * bs_number +bs_number*user_number+ bs_number * bs_number + bs_number + user_number:]\n","\n","    # print(\"--------------------------------state----------------------------\")\n","    # print(\"-------------------user_bs_snr_status------------------\")\n","    # print(user_bs_snr_status)\n","    # print(\"-----------------------bs_user_snr_status--------------\")\n","    # print(bs_user_snr_status)\n","    # print(\"---------------bs_snr_status-------------------\")\n","    # print(bs_snr_status)\n","    # print(\"---------------bs_comp_status----------------\")\n","    # print(bs_comp_status)\n","    # print(\"-----------------user_comp_status---------------\")\n","    # print(user_comp_status)\n","    # print(\"-----------------user_compmittee----------------\")\n","    # print(user_committee_status)\n","    # print(\"---------------------user_good_status-------------\")\n","    # print(user_isGood)\n","\n","    \n","    #number of committee workers\n","    K=0\n","    for i in user_committee_status:\n","      if i == 1:\n","        K = K + 1\n","    \n","\n","\n","\n","    # print(\"----------------K------------------\")\n","    # print(K)\n","\n","\n","\n","    #由于action不会改变状态，不需要根绝action对status修正。只需要根据state和action计算reward和限制条件。\n","    action_number = np.size(action)\n","    if module == 1:\n","        action[:extra_channel] = np.array([1]*(extra_channel))\n","    elif module == 2:\n","        action[extra_channel] = 11*(10**6) # 固定6M的block_size\n","    elif module == 3:\n","        action[-1] = 3 #固定block_producer为1号\n","\n","    allocated_channel =np.array([1]*(user_number + bs_number)) #前user_number个数代表给用户分配的信道数，后bs_number个数代表给基站分配的信道数\n","    for i in range(action_number - 2):\n","        index = action[i] \n","        allocated_channel[index-1]+=extra_channel*(channel_number-bs_number-user_number)\n","\n","    user_allocated_channel = allocated_channel[:user_number]\n","    bs_allocated_channel = allocated_channel[user_number:user_number + bs_number]\n","\n","    #blocksize\n","    block_size=action[-2]\n","    \n","    #producer的序号\n","    producer=action[-1]\n","\n","    # print(\"--------------------------action--------------------------\")\n","    # print(\"------------user_allocated_channel------------\")\n","    # print(user_allocated_channel)\n","    # print(\"------------bs_allocated_channel------------\")\n","    # print(bs_allocated_channel)\n","    # print(\"---------------blocksize---------------\")\n","    # print(block_size)\n","    # print(\"---------producer-----------\")\n","    # print(producer)\n","\n","\n"," #FL的能耗与时延\n","\n","  #(1) Local model融合得到global model及global model的广播\n","    producer_fuse_cpu_cycles=theta_3*K\n","    # print(\"---------producer_fuse_cpu_cycles-----------\")\n","    # print(producer_fuse_cpu_cycles)\n","    producer_fuse_delay=producer_fuse_cpu_cycles/bs_comp_status[producer-1]\n","    # print(\"-------------producer_fuse_delay---------------\")\n","    # print(producer_fuse_delay)\n","    primary_user_snr=bs_user_snr_status[producer-1,:]\n","    primary_user_rate=bs_allocated_channel[producer-1]*bandwidth*np.log2(1+primary_user_snr) \n","    # print(\"-------------primary_user_rate---------------\")\n","    # print(primary_user_rate)\n","\n","    primary_user_delay=omega/primary_user_rate\n","    primary_user_ec=primary_user_delay*power_b\n","    # print(\"-------------primary_user_ec---------------\")\n","    # print(primary_user_ec)\n","\n","\n","  #(2) Workers当地训练及上传\n","    #committee workers验证global model的CPU消耗和时间消耗\n","    committeer_validate_global_model_cpu_cycles=user_isGood*user_committee_status*theta_2*user_data_size\n","    # print(\"-------------committeer_validate_global_model_cpu_cycles---------------\")\n","    # print(committeer_validate_global_model_cpu_cycles)\n","    committeer_validate_global_model_delay=committeer_validate_global_model_cpu_cycles/user_comp_status\n","    # print(\"-------------committeer_validate_global_model_delay---------------\")\n","    # print(committeer_validate_global_model_delay)\n","\n","    \n","    #committee workers上传global model的score(忽略)\n","\n","    #workers进行local training的CPU消耗与时间消耗\n","    user_train_cpu_cycles=user_isGood*user_committee_status*theta_1*user_data_size\n","    # print(\"-------------user_train_cpu_cycles---------------\")\n","    # print(user_train_cpu_cycles)\n","    user_train_delay=user_train_cpu_cycles/user_comp_status\n","    # print(\"-------------user_train_delay---------------\")\n","    # print(user_train_delay)\n","    \n","    #workers上传global model\n","    user_primary_snr=user_bs_snr_status[:,producer-1]\n","    user_primary_rate=user_allocated_channel*bandwidth*np.log2(1+user_primary_snr)\n","    # print(\"-------------user_primary_rate---------------\")\n","    # print(user_primary_rate)\n","    user_primary_delay=omega/user_primary_rate\n","    user_primary_ec=user_primary_delay*power_u\n","    # print(\"-------------user_primary_ec---------------\")\n","    # print(user_primary_ec)\n","    \n","  #(3) Committee workers的验证及score的上传\n","    #将M个local model传播给committee workers时延以及能耗\n","    primary_committee_delay=user_committee_status*user_number*omega/primary_user_rate\n","    # print(\"-------------primary_committee_delay---------------\")\n","    # print(primary_committee_delay)\n","    primary_committee_ec=primary_committee_delay*power_b\n","    # print(\"-------------primary_committee_ec---------------\")\n","    # print(primary_committee_ec)\n","    #committee workers的验证\n","    committeer_validate_local_model_cpu_cycles=user_isGood*user_committee_status*user_number*theta_2*user_data_size\n","    # print(\"-------------committeer_validate_local_model_cpu_cycles---------------\")\n","    # print(committeer_validate_local_model_cpu_cycles)\n","    committeer_validate_local_model_delay=committeer_validate_local_model_cpu_cycles/user_comp_status\n","    # print(\"-------------committeer_validate_local_model_delay---------------\")\n","    # print(committeer_validate_local_model_delay)\n","    #score的上传（忽略）\n","  #(4) score的统计（忽略）\n","\n","  #计算FL的总能耗与时间消耗\n","    \n","    #能耗\n","    #producer的计算能耗\n","    Bp_ec=(10**27)*epsilon*(bs_comp_status[producer-1]**2)*producer_fuse_cpu_cycles\n","    # print(\"-------------Bp_ec---------------\")\n","    # print(Bp_ec)\n","\n","    #传输总能耗\n","    trans_FL_ec=np.sum(primary_user_ec)+np.sum(user_primary_ec)+np.sum(primary_committee_ec)\n","    # print(\"-------------trans_FL_ec---------------\")\n","    # print(trans_FL_ec)\n","\n","    #user的计算总能耗\n","    train_and_validate_ec=(10**27)*epsilon*(np.sum((user_comp_status**2)*committeer_validate_global_model_cpu_cycles)\\\n","                    +np.sum((user_comp_status**2)*user_train_cpu_cycles)\\\n","                    +np.sum((user_comp_status**2)*committeer_validate_local_model_cpu_cycles))\n","    # print(\"-------------train_and_validate_ec---------------\")\n","    # print(train_and_validate_ec)\n","\n","    \n","    total_FL_ec=Bp_ec+trans_FL_ec+train_and_validate_ec\n","\n","    # print(\"-------------total_FL_ec---------------\")\n","    # print(total_FL_ec)\n","\n","    #时间消耗\n","    total_FL_delay=producer_fuse_delay\\\n","           +np.max(primary_user_delay+\\\n","            (committeer_validate_global_model_delay+user_train_delay)+user_primary_delay)\\\n","           +np.max(primary_committee_delay+committeer_validate_local_model_delay)\n","\n","    # print(\"-------------total_FL_delay---------------\")\n","    # print(total_FL_delay)\n","\n"," #BC的能耗与时延\n","  #传输时延\n","    bs_rate = bandwidth * np.transpose([bs_allocated_channel]) * np.log2(1 + bs_snr_status) # 对应基站到基站的传输速率\n","    for i in range(len(bs_rate)):\n","      bs_rate[i,i]=-1\n","    # print(bs_rate)\n","  #(2) pre_prepare\n","    primary_bs_rate = bs_rate[producer - 1, :]\n","    pre_p_trans_delay =  block_size*8/primary_bs_rate\n","    pre_p_trans_delay = np.where(pre_p_trans_delay>0,pre_p_trans_delay,0)\n","    # print(\"-------------pre_p_trans_delay---------------\")\n","    # print(pre_p_trans_delay)\n","\n","  #(3) prepare\n","    pre_bs_rate = np.delete(bs_rate, producer - 1, axis=0)\n","    pre_trans_delay = block_size*8/pre_bs_rate\n","    pre_trans_delay = np.where(pre_trans_delay>0,pre_trans_delay,0)\n","    # print(\"-------------pre_trans_delay---------------\")\n","    # print(pre_trans_delay)\n","\n","  #(4) commit    \n","    com_trans_delay = block_size*8/bs_rate\n","    com_trans_delay = np.where(com_trans_delay>0,com_trans_delay,0)\n","    # print(\"-------------com_trans_delay---------------\")\n","    # print(com_trans_delay)\n","  #(5) reply\n","    rep_bs_primary_rate = bs_rate[:,producer-1]\n","    rep_trans_delay = block_size*8/rep_bs_primary_rate\n","    rep_trans_delay = np.where(rep_trans_delay>0,rep_trans_delay,0)\n","    # print(\"-------------rep_trans_delay--------------\")\n","    # print(rep_trans_delay)\n","\n","  #计算时间\n","  #(1) 验证M+1个交易的签名和MAC   \n","    bs_validate_transition_cpu_cycles=np.array([0.] * bs_number)\n","    bs_validate_transition_cpu_cycles[producer-1]=(block_size*8/omega)*(alpha+beta)\n","    bs_validate_transition_delay=np.max(bs_validate_transition_cpu_cycles/bs_comp_status)\n","    # print(\"-------------bs_validate_transition_delay---------------\")\n","    # print(bs_validate_transition_cpu_cycles/bs_comp_status)\n","  \n","  #(2) pre_prepare\n","    bs_pre_p_cpu_cycles=np.array([1.] * bs_number)\n","    bs_pre_p_cpu_cycles=bs_pre_p_cpu_cycles*(alpha+beta+(block_size*8/omega)*(alpha+beta))\n","    bs_pre_p_cpu_cycles[producer-1]=alpha+(bs_number-1)*beta\n","    bs_pre_p_comp_delay=np.max(bs_pre_p_cpu_cycles/bs_comp_status)\n","    # print(\"-------------bs_pre_p_comp_delay---------------\")\n","    # print(bs_pre_p_cpu_cycles/bs_comp_status)\n","  #(3) prepare\n","    bs_pre_cpu_cycles=np.array([1.] * bs_number)\n","    bs_pre_cpu_cycles=bs_pre_cpu_cycles*(alpha+(bs_number-1)*beta+2*faulty_nodes*(alpha+beta))\n","    bs_pre_cpu_cycles[producer-1]=2*faulty_nodes*(alpha+beta)\n","    bs_pre_comp_delay=np.max(bs_pre_cpu_cycles/bs_comp_status)\n","    # print(\"-------------bs_pre_comp_delay---------------\")\n","    # print(bs_pre_cpu_cycles/bs_comp_status)\n","\n","  #(4) commit\n","    bs_commit_cpu_cycles=np.array([1.] * bs_number)\n","    bs_commit_cpu_cycles=bs_commit_cpu_cycles*(alpha+(bs_number-1)*beta+2*faulty_nodes*(alpha+beta))\n","    bs_commit_comp_delay=np.max(bs_commit_cpu_cycles/bs_comp_status)\n","    # print(\"-------------bs_commit_comp_delay---------------\")\n","    # print(bs_commit_cpu_cycles/bs_comp_status)\n","   \n","  #(5) reply\n","    bs_reply_cpu_cycles=np.array([1.] * bs_number)\n","    # bs_reply_cpu_cycles=bs_reply_cpu_cycles*((block_size*8/omega)*(alpha+beta))\n","    bs_reply_cpu_cycles=bs_reply_cpu_cycles*(alpha+beta)\n","    bs_reply_cpu_cycles[producer-1]=2*faulty_nodes*(alpha+beta)\n","    # print(bs_reply_cpu_cycles)\n","    bs_reply_comp_delay=np.max(bs_reply_cpu_cycles/bs_comp_status)\n","    # print(\"-------------bs_reply_comp_delay--------------\")\n","    # print(bs_reply_cpu_cycles/bs_comp_status)\n","  \n","  \n","  #时间消耗：\n","    total_BC_delay=np.max(pre_p_trans_delay)+np.max(pre_trans_delay)+np.max(com_trans_delay)\\\n","    +np.max(rep_trans_delay)\\\n","    +bs_validate_transition_delay+bs_pre_p_comp_delay+bs_pre_comp_delay+bs_commit_comp_delay\\\n","    +bs_reply_comp_delay\n","    # print(\"-------------total_BC_delay---------------\")\n","    # print(total_BC_delay)\n","\n","  #能耗\n","  #传输能耗\n","    trans_BC_ec=np.ceil((user_number+1)*omega/(block_size*8))*np.sum(pre_p_trans_delay)*power_b+np.sum(pre_trans_delay)*power_b\\\n","    +np.sum(com_trans_delay)*power_b+np.sum(rep_trans_delay)*power_b\n","    # print(\"-------------trans_BC_ec---------------\")\n","    # print(trans_BC_ec)\n","\n","  #计算能耗\n","    total_cpu_cycles=(bs_validate_transition_cpu_cycles+bs_pre_p_cpu_cycles+bs_pre_cpu_cycles\\\n","    +bs_commit_cpu_cycles+bs_reply_cpu_cycles)\n","    # print(\"-------------total_cpu_cycles---------------\")\n","    # print(total_cpu_cycles)\n","    comp_BC_ec=np.ceil((user_number+1)*omega/(block_size*8))*np.sum((10**27)*epsilon*(bs_comp_status**2)*(total_cpu_cycles))\n","    # print(\"-------------comp_BC_ec---------------\")\n","    # print(comp_BC_ec)\n","    \n","  #BC总能耗\n","    total_BC_ec=trans_BC_ec+comp_BC_ec\n","    # print(\"-------------total_BC_ec---------------\")\n","    # print(total_BC_ec)\n"," #总能耗\n","    total_ec=total_FL_ec+total_BC_ec\n","    \n","    \n"," #reward\n","    if total_FL_delay>time_to_fl_limit or total_BC_delay>time_to_bc_limit:\n","      reward=0\n","    else:\n","      reward=10000/total_ec\n","      #reward=2000*(1/(trans_FL_ec+trans_BC_ec)+74/comp_BC_ec)\n","      # reward=2000*(1/(trans_FL_ec+trans_BC_ec)+400/comp_BC_ec)\n","      # j1.append(trans_FL_ec+trans_BC_ec)\n","      # j2.append(comp_BC_ec)\n","    # print(\"trans_FL_ec+trans_BC_ec: \"+str(trans_FL_ec+trans_BC_ec))\n","    # print(\"comp_BC_ec: \"+str(comp_BC_ec))\n","    # print(\"total_ec: \"+str(total_ec))\n","      \n","#状态转移\n","    for i in range(user_number):\n","        for j in range(bs_number):\n","            temp = random.uniform(0,1)\n","            if user_bs_snr_status[i, j] == 1:\n","                if temp < 0.1:\n","                    user_bs_snr_status[i, j] = 15\n","                elif temp<0.4:\n","                    user_bs_snr_status[i, j] = 7\n","            if user_bs_snr_status[i, j] == 7:\n","                if temp < 0.6:\n","                    user_bs_snr_status[i, j] = 15\n","                elif temp < 0.9:\n","                    user_bs_snr_status[i, j] = 1\n","            if user_bs_snr_status[i, j] == 15:\n","                if temp < 0.1:\n","                    user_bs_snr_status[i, j] = 1\n","                elif temp < 0.7:\n","                    user_bs_snr_status[i, j] = 7\n","                    \n","    for i in range(bs_number):\n","        for j in range(user_number):\n","            temp = random.uniform(0,1)\n","            if bs_user_snr_status[i, j] == 1:\n","                if temp < 0.1:\n","                    bs_user_snr_status[i, j] = 15\n","                elif temp<0.4:\n","                    bs_user_snr_status[i, j] = 7\n","            if bs_user_snr_status[i, j] == 7:\n","                if temp < 0.6:\n","                    bs_user_snr_status[i, j] = 15\n","                elif temp < 0.9:\n","                    bs_user_snr_status[i, j] = 1\n","            if bs_user_snr_status[i, j] == 15:\n","                if temp < 0.1:\n","                    bs_user_snr_status[i, j] = 1\n","                elif temp < 0.7:\n","                    bs_user_snr_status[i, j] = 7\n","    for i in range(bs_number):\n","        for j in range(bs_number):\n","            if i==j:\n","                bs_snr_status[i, j] = 1\n","            else:\n","                temp = random.uniform(0,1)\n","                if bs_snr_status[i, j] == 1:\n","                    if temp < 0.1:\n","                        bs_snr_status[i, j] = 15\n","                    elif temp<0.4:\n","                        bs_snr_status[i, j] = 7\n","                if bs_snr_status[i, j] == 7:\n","                    if temp < 0.6:\n","                        bs_snr_status[i, j] = 15\n","                    elif temp < 0.9:\n","                        bs_snr_status[i, j] = 1\n","                if bs_snr_status[i, j] == 15:\n","                    if temp < 0.1:\n","                        bs_snr_status[i, j] = 1\n","                    elif temp < 0.7:\n","                        bs_snr_status[i, j] = 7\n","                    \n","    for i in range(bs_number):\n","        bs_comp=bs_comp_status[i]\n","        temp = random.uniform(0,1)\n","        if bs_comp == bs_comp_capacity[0]:\n","          if temp < computation_state[0][1]:\n","              bs_comp_status[i] = bs_comp_capacity[1]\n","          elif temp < computation_state[0][1]+computation_state[0][2]:\n","              bs_comp_status[i] = bs_comp_capacity[2]\n","        if bs_comp == bs_comp_capacity[1]:\n","          if temp < computation_state[1][0]:\n","              bs_comp_status[i] = bs_comp_capacity[0]\n","          elif temp < computation_state[1][0]+computation_state[1][2]:\n","              bs_comp_status[i] = bs_comp_capacity[2]\n","        if bs_comp == bs_comp_capacity[2]:\n","          if temp < computation_state[2][0]:\n","              bs_comp_status[i] = bs_comp_capacity[0]\n","          elif temp < computation_state[2][0]+computation_state[2][1]:\n","              bs_comp_status[i] = bs_comp_capacity[1]\n","    for i in range(user_number):\n","        user_comp=user_comp_status[i]\n","        temp = random.uniform(0,1)\n","        if user_comp == user_comp_capacity[0]:\n","          if temp < 0.2:\n","              user_comp_status[i] = user_comp_capacity[1]\n","          elif temp < 0.3:\n","              user_comp_status[i] = user_comp_capacity[2]\n","        if bs_comp == user_comp_capacity[1]:\n","          if temp < 0.2:\n","              user_comp_status[i] = user_comp_capacity[0]\n","          elif temp < 0.9:\n","              user_comp_status[i] = user_comp_capacity[2]\n","        if bs_comp == user_comp_capacity[2]:\n","          if temp < 0.1:\n","              user_comp_status[i] = user_comp_capacity[0]\n","          elif temp < 0.8:\n","              user_comp_status[i] = user_comp_capacity[1]\n","                \n","    \n","    \n","    # 将新的shape整合成原先的shape\n","    user_bs_snr_status = np.reshape(user_bs_snr_status, user_number * bs_number)\n","    bs_user_snr_status = np.reshape(bs_user_snr_status, bs_number * user_number)\n","    bs_snr_status = np.reshape(bs_snr_status, bs_number * bs_number)\n","    \n","    # print(\"----------------------------------------state_-------------------------------\")\n","    # print(user_bs_snr_status)\n","    # print(bs_user_snr_status)\n","    # print(bs_snr_status)\n","    # print(bs_comp_status)\n","    # print(user_comp_status)\n","\n","    state_ = np.concatenate((user_bs_snr_status, bs_user_snr_status, bs_snr_status, bs_comp_status, user_comp_status))\n","    \n","    \n","    return state_, reward, total_ec\n","  \n","    \n","\n","#联邦学习模型\n","class FL:\n","    def __init__(self,name,sess,data=None,label=None,isCommittee=False,isBad=False,lr=0.0005):\n","        self.lr=lr    #LEARNING_RATE\n","        self.sess=sess\n","        self.name=name\n","        self.c_name=self.name+\"params\"\n","        self.parameters=self.build_net(self.c_name)\n","        self.data=data\n","        self.label=label\n","        self.isCommittee=isCommittee\n","        self.isBad=isBad\n","        \n","        \n","        \n","    def build_net(self,c_name):\n","        CONV_SIZE = 3\n","        CONV_1_KERNAL = 32 \n","        CONV_2_KERNAL = 64\n","        \n","        W_INITIALIZER=tf.truncated_normal_initializer(0,0.05)\n","        B_INITIALIZER=tf.constant_initializer(0.03)\n","\n","                    \n","        # 卷积神经网络\n","        def params(name,shape,initializer,c_names):\n","            return tf.get_variable(name,shape,initializer=initializer,collections=c_names)\n","        \n","        def conv2d(x,w):\n","            return tf.nn.conv2d(x,w,strides=[1,1,1,1],padding=\"SAME\")\n","        \n","        def pool(x):\n","            return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding=\"SAME\")\n","        \n","        self.x=tf.placeholder(tf.float32,[None,784],name=\"input_features\")\n","        self.y=tf.placeholder(tf.float32,[None,10],name=\"actual_labels\")\n","        self.keep_prob=tf.placeholder(tf.float32,name=\"keep_prob\")\n","        image_x=tf.reshape(self.x,[-1,28,28,1])\n","        \n","        c_names=[tf.GraphKeys.GLOBAL_VARIABLES,c_name]\n","        with tf.variable_scope(\"conv_1\"):\n","            conv_1_w=params(\"conv_1_w\",[CONV_SIZE,CONV_SIZE,1,CONV_1_KERNAL],W_INITIALIZER,c_names)\n","            conv_1_b=params(\"conv_1_b\",CONV_1_KERNAL,B_INITIALIZER,c_names)\n","            conv_1_out=tf.nn.relu(conv2d(image_x,conv_1_w)+conv_1_b)\n","            l1=tf.nn.dropout(pool(conv_1_out),self.keep_prob)\n","        \n","        \n","        with tf.variable_scope(\"conv_2\"):\n","            conv_2_w=params(\"conv_2_w\",[CONV_SIZE,CONV_SIZE,CONV_1_KERNAL,CONV_2_KERNAL],W_INITIALIZER,c_names)\n","            conv_2_b=params(\"conv_2_b\",CONV_2_KERNAL,B_INITIALIZER,c_names)\n","            conv_2_out=tf.nn.relu(conv2d(l1,conv_2_w)+conv_2_b)\n","            l2=tf.nn.dropout(pool(conv_2_out),self.keep_prob)\n","        \n","        with tf.variable_scope(\"fc_1\"):\n","            flattened_input=tf.reshape(l2,[-1,7*7*CONV_2_KERNAL])\n","            fc_1_w=params(\"fc_1_w\",[7*7*CONV_2_KERNAL,512],W_INITIALIZER,c_names)\n","            fc_1_b=params(\"fc_1_b\",512,B_INITIALIZER,c_names)\n","            l4=tf.nn.dropout(tf.nn.relu(tf.matmul(flattened_input,fc_1_w)+fc_1_b),self.keep_prob)\n","            \n","        with tf.variable_scope(\"fc_2\"):\n","            fc_2_w=params(\"fc_2_w\",[512,10],W_INITIALIZER,c_names)\n","            fc_2_b=params(\"fc_2_b\",10,B_INITIALIZER,c_names)\n","            output=tf.nn.softmax(tf.matmul(l4,fc_2_w)+fc_2_b)  \n","        \n","             \n","        \n","        with tf.variable_scope(\"loss\"):\n","            self.loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=self.y,logits=output))\n","            \n","        with tf.variable_scope(\"accuracy\"):\n","            self.accuracy=tf.reduce_mean(tf.cast(tf.equal(tf.argmax(self.y,axis=1),tf.argmax(output,axis=1)),tf.float32))\n","            \n","        with tf.variable_scope(\"train\"):\n","            # self.train_op=tf.train.RMSPropOptimizer(self.lr).minimize(self.loss)\n","            self.Optimizer=tf.train.RMSPropOptimizer(self.lr)\n","            self.train_op=self.Optimizer.minimize(self.loss)\n","        \n","        return tf.get_collection(c_name)\n","\n","    def train(self):\n","        batch_size=100\n","        n_batch=int(self.data.shape[0]/batch_size) \n","        for i in range(n_batch):\n","            self.sess.run(self.train_op,feed_dict={self.x:self.data[i*batch_size:(i+1)*batch_size],\n","                  self.y:self.label[i*batch_size:(i+1)*batch_size],\n","                  self.keep_prob:1.0})\n","          \n","\n","    def validate(self,data,label):\n","        batch_size=100\n","        n_batch=int(data.shape[0]/batch_size)\n","        acc=0\n","        for i in range(n_batch):\n","          x=self.sess.run(self.accuracy,feed_dict={self.x:data[i*batch_size:(i+1)*batch_size],\n","                              self.y:label[i*batch_size:(i+1)*batch_size],\n","                              self.keep_prob:1.0})\n","          acc+=(x/n_batch)\n","        return acc\n","\n","\n","#DRL模型\n","class DDQN:\n","    def __init__(\n","            self,\n","            n_actions,\n","            n_features,\n","            learning_rate=0.001,\n","            reward_decay=0.9,  # 腐蚀率  \n","            e_greedy=0.9,  # 探索新事物的概率\n","            replace_target_iter=300,\n","            memory_size=3000,\n","            batch_size=32,\n","            e_greedy_increment=0.0001,\n","            dueling=False,\n","            sess=None,\n","    ):\n","        self.n_actions = n_actions\n","        self.n_features = n_features\n","        self.lr = learning_rate\n","        self.gamma = reward_decay\n","        self.epsilon_max = e_greedy\n","        self.replace_target_iter = replace_target_iter\n","        self.memory_size = memory_size\n","        self.batch_size = batch_size\n","        self.epsilon_increment = e_greedy_increment\n","        self.epsilon = 0 if e_greedy_increment is not None else self.epsilon_max\n","        \n","        self.dueling = dueling      # decide to use dueling DQN or not\n","\n","        self.learn_step_counter = 0\n","        self.memory = np.zeros((self.memory_size, n_features*2+2))\n","        self._build_net()\n","        t_params = tf.get_collection('target_net_params')\n","        e_params = tf.get_collection('eval_net_params')\n","        self.replace_target_op = [tf.assign(t, e) for t, e in zip(t_params, e_params)]\n","\n","        if sess is None:\n","            self.sess = tf.Session()\n","            self.sess.run(tf.global_variables_initializer())\n","        else:\n","            self.sess = sess\n","        self.cost_his=[]\n","\n","\n","    def _build_net(self):\n","        def build_layers(s, c_names, n_l1, n_l2, n_l3, w1_initializer,w2_initializer, w3_initializer, w4_initializer, w5_initializer, b_initializer):\n","            with tf.variable_scope('l1'):\n","                w1 = tf.get_variable('w1', [self.n_features, n_l1], initializer=w1_initializer, collections=c_names)\n","                b1 = tf.get_variable('b1', [1, n_l1], initializer=b_initializer, collections=c_names)\n","                l1 = tf.nn.relu(tf.matmul(s, w1) + b1)\n","                \n","            with tf.variable_scope('l2'):\n","                w2 = tf.get_variable('w2', [n_l1, n_l2], initializer=w2_initializer, collections=c_names)\n","                b2 = tf.get_variable('b2', [1, n_l2], initializer=b_initializer, collections=c_names)\n","                l2 = tf.nn.relu(tf.matmul(l1, w2) + b2)\n","                \n","            with tf.variable_scope('l3'):\n","                w3 = tf.get_variable('w3', [n_l2, n_l3], initializer=w3_initializer, collections=c_names)\n","                self.w3=w3\n","                b3 = tf.get_variable('b3', [1, n_l3], initializer=b_initializer, collections=c_names)\n","                l3 = tf.nn.relu(tf.matmul(l2, w3) + b3)                \n","\n","            if self.dueling:\n","                # Dueling DQN\n","                with tf.variable_scope('Value'):\n","                    w4 = tf.get_variable('w4', [n_l3, 1], initializer=w4_initializer, collections=c_names)\n","                    b4 = tf.get_variable('b4', [1, 1], initializer=b_initializer, collections=c_names)\n","                    self.V = tf.matmul(l3, w4) + b4\n","\n","                with tf.variable_scope('Advantage'):\n","                    w4 = tf.get_variable('w4', [n_l3, self.n_actions], initializer=w5_initializer, collections=c_names)\n","                    b4 = tf.get_variable('b4', [1, self.n_actions], initializer=b_initializer, collections=c_names)\n","                    self.A = tf.matmul(l3, w4) + b4\n","\n","                with tf.variable_scope('Q'):\n","                    out = self.V + (self.A - tf.reduce_mean(self.A, axis=1, keep_dims=True))     # Q = V(s) + A(s,a)\n","            else:\n","                with tf.variable_scope('Q'):\n","                    w4 = tf.get_variable('w4', [n_l3, self.n_actions], initializer=w5_initializer, collections=c_names)\n","                    b4 = tf.get_variable('b4', [1, self.n_actions], initializer=b_initializer, collections=c_names)\n","                    out = tf.matmul(l3, w4) + b4\n","\n","            return out\n","\n","\n","        # ------------------ build evaluate_net ------------------\n","        self.s = tf.placeholder(tf.float32, [None, self.n_features], name='s')  # input\n","        self.q_target = tf.placeholder(tf.float32, [None, self.n_actions], name='Q_target')  # for calculating loss\n","        \n","        with tf.variable_scope('eval_net'):\n","            c_names, n_l1, n_l2, n_l3, w1_initializer, w2_initializer, w3_initializer,w4_initializer, w5_initializer,b_initializer = \\\n","                ['eval_net_params', tf.GraphKeys.GLOBAL_VARIABLES], 256 ,256 ,128, \\\n","                tf.random_normal_initializer(stddev=(2/(32 + 256))**0.5), tf.random_normal_initializer(stddev=(2/512)**0.5),\\\n","                tf.random_normal_initializer(stddev=(2/384)**0.5), tf.random_normal_initializer(stddev=(2/129)**0.5),\\\n","                tf.random_normal_initializer(stddev=(2/(128 + 112))**0.5), tf.constant_initializer(0.1)  # config of layers\n","\n","            self.q_eval = build_layers(self.s, c_names, n_l1, n_l2, n_l3, w1_initializer, w2_initializer, w3_initializer,w4_initializer,w5_initializer, b_initializer)\n","\n","        with tf.variable_scope('loss'):\n","            self.loss = tf.reduce_mean(tf.squared_difference(self.q_target, self.q_eval))\n","        with tf.variable_scope('train'):  \n","            self._train_op = tf.train.AdamOptimizer(learning_rate=self.lr).minimize(self.loss)\n","\n","        # ------------------ build target_net ------------------\n","        self.s_ = tf.placeholder(tf.float32, [None, self.n_features], name='s_')   \n","        with tf.variable_scope('target_net'):\n","            c_names = ['target_net_params', tf.GraphKeys.GLOBAL_VARIABLES]\n","\n","            self.q_next = build_layers(self.s_, c_names, n_l1, n_l2, n_l3, w1_initializer, w2_initializer, w3_initializer, w4_initializer, w5_initializer, b_initializer)\n","\n","    def store_transition(self, s, a, r, s_):\n","        if not hasattr(self, 'memory_counter'):\n","            self.memory_counter = 0\n","        transition = np.hstack((s, [a, r], s_))\n","        index = self.memory_counter % self.memory_size\n","        self.memory[index, :] = transition\n","        self.memory_counter += 1\n","\n","      \n","    def choose_action(self, observation):\n","        # to have batch dimension when feed into tf placeholder\n","        observation = observation[np.newaxis, :]\n","        actions_value = self.sess.run(self.q_eval, feed_dict={self.s: observation})\n","        action_index = np.argmax(actions_value)\n","        \n","        action_number = channel_number - bs_number - user_number + 2\n","        action = np.array([1] * action_number)\n","        random_number=np.random.uniform()\n","        if random_number < self.epsilon:\n","            action_index = action_index\n","        else:\n","            action_index = np.random.randint(0, n_actions)           \n","        action = theNiubiFunction(action_index)\n","        # print(\"---------------action_index--------------\")\n","        # print(action_index)\n","        # print(\"--------------action---------------\")\n","        # print(action)\n","        return action, action_index\n","  \n","\n","    def learn(self):\n","        if self.learn_step_counter % self.replace_target_iter == 0:\n","            self.sess.run(self.replace_target_op)\n","            \n","        sample_index = np.random.choice(self.memory_size, size=self.batch_size)\n","        batch_memory = self.memory[sample_index, :]\n","\n","        q_next, q_eval4next = self.sess.run([self.q_next, self.q_eval], feed_dict={self.s_: batch_memory[:, -self.n_features:],\n","                                                                                  self.s:batch_memory[:, -self.n_features:]}) # next observation\n","        q_eval = self.sess.run(self.q_eval, {self.s: batch_memory[:, :self.n_features]})\n","\n","        q_target = q_eval.copy()\n","\n","        batch_index = np.arange(self.batch_size, dtype=np.int32)\n","        eval_act_index = batch_memory[:, self.n_features].astype(int)\n","        reward = batch_memory[:, self.n_features + 1]\n","        \n","\n","        selected_q_next = np.max(q_next, axis=1)  # the natural DQN\n","            \n","        \n","        q_target[batch_index, eval_act_index] = reward + self.gamma * selected_q_next  \n","\n","        _, self.cost = self.sess.run([self._train_op, self.loss],\n","                                     feed_dict={self.s: batch_memory[:, :self.n_features],\n","                                                self.q_target: q_target})\n","        self.cost_his.append(self.cost)\n","\n","        self.epsilon = self.epsilon + self.epsilon_increment if self.epsilon < self.epsilon_max else self.epsilon_max\n","        self.learn_step_counter += 1\n","\n","    def plot_cost(self):\n","        plt.plot(np.arange(len(self.cost_his)), self.cost_his)\n","        plt.ylabel('Cost')\n","        plt.xlabel('training steps')\n","        plt.grid(True)\n","        plt.show()\n","\n","\n","\n","\n","def broadcast(all_user_FL,global_FL,global_sess):\n","  global_model_broadcast=[]\n","  for user_FL in all_user_FL:\n","    global_model_broadcast+=[tf.assign(e,t) for e,t in zip(user_FL.parameters,global_FL.parameters)]\n","  global_sess.run(global_model_broadcast)\n","\n","def committee_validate(committee_FL,all_user_FL,global_sess):\n","  all_user_FL_scores=[]\n","  if committee_FL.isBad==False:\n","    for user_FL in all_user_FL:\n","      all_user_FL_scores.append(user_FL.validate(committee_FL.data,committee_FL.label))\n","  else:\n","    for user_FL in all_user_FL:\n","      if user_FL.isBad==True:\n","        all_user_FL_scores.append(1.0)\n","      else:\n","        all_user_FL_scores.append(0.0)\n","  return all_user_FL_scores\n","\n","\n","tao=0.05\n","\n","def get_next_global_model_and_commmittee_users(all_user_FL,global_model,all_user_FL_scores,global_model_score,global_sess):\n","  all_user_number=len(all_user_FL)\n","  global_sess.run([tf.assign(t,0*e) for t,e in zip(global_model.parameters,global_model.parameters)])\n","  k=0\n","  for i in range(all_user_number):\n","    all_user_FL[i].isCommittee=False\n","    score=all_user_FL_scores[i]\n","    if(score>global_model_score):\n","      k=k+1\n","      all_user_FL[i].isCommittee=True\n","      global_sess.run([tf.assign(t,e+t) for t,e in zip(global_model.parameters,all_user_FL[i].parameters)])\n","  if k!=0:\n","    global_sess.run([tf.assign(t,e/k) for t,e in zip(global_model.parameters,global_model.parameters)])\n","  else:\n","    for i in range(all_user_number):\n","      all_user_FL[i].isCommittee=False\n","      score=all_user_FL_scores[i]\n","      if(score>global_model_score*(1-tao)):\n","        k=k+1\n","        all_user_FL[i].isCommittee=True\n","        global_sess.run([tf.assign(t,e+t) for t,e in zip(global_model.parameters,all_user_FL[i].parameters)])\n","    if k!=0:\n","      global_sess.run([tf.assign(t,e/k) for t,e in zip(global_model.parameters,global_model.parameters)])\n","    else:\n","      for i in range(all_user_number):\n","        all_user_FL[i].isCommittee=True\n","        global_sess.run([tf.assign(t,e+t) for t,e in zip(global_model.parameters,all_user_FL[i].parameters)])\n","      global_sess.run([tf.assign(t,e/all_user_number) for t,e in zip(global_model.parameters,global_model.parameters)])\n","  isCommittee=[0 for i in range(all_user_number)]\n","  for i in range(all_user_number):\n","    if(all_user_FL[i].isCommittee==True):\n","      isCommittee[i]=1\n","  return isCommittee\n","\n","def local_train(all_user_FL,global_sess):\n","  for user_FL in all_user_FL:\n","    if user_FL.isBad==False:\n","      user_FL.train()\n","    else:\n","      global_sess.run([tf.assign(t,0*e) for  t,e in zip(user_FL.parameters,user_FL.parameters)])\n","\n","\n","def get_global_model_score(all_user_FL,global_model,global_sess):\n","  global_model_score=[]\n","  for user_FL in all_user_FL:\n","    if user_FL.isCommittee==True:\n","      if user_FL.isBad==False:\n","        global_model_score.append(global_model.validate(user_FL.data,user_FL.label))\n","      else:\n","        global_model_score.append(0.999999)\n","  delta=np.std(global_model_score)\n","  mean=np.mean(global_model_score)\n","  for i in range(len(global_model_score)-1,-1,-1):\n","    x=global_model_score[i]\n","    if x<mean-delta or x>mean+delta:\n","      global_model_score.remove(x)\n","  # print(\"global_model_score: \"+str(np.mean(global_model_score)))\n","  return np.mean(global_model_score)\n","\n","\n","def get_all_user_FL_scores(all_user_FL,global_sess):\n","  all_user_number=len(all_user_FL)\n","  committee_to_all_user_FL_scores=[]\n","  for user_FL in all_user_FL:\n","    if user_FL.isCommittee==True:\n","      committee_to_all_user_FL_scores.append(committee_validate(user_FL,all_user_FL,global_sess))\n","  all_user_FL_scores=[]\n","  mean=np.mean(committee_to_all_user_FL_scores,0)\n","  delta=np.std(committee_to_all_user_FL_scores,0)\n","  for i in range(all_user_number):\n","    scores=np.array(committee_to_all_user_FL_scores)[:,i]\n","    for j in range(len(scores)-1,-1,-1):\n","      x=scores[j]\n","      if x<mean[i]-delta[i] or x>mean[i]+delta[i]:\n","        scores=np.delete(scores,[j])\n","    all_user_FL_scores.append(np.mean(scores))\n","  # print(\"all_user_FL_scores: \"+str(all_user_FL_scores))\n","  return all_user_FL_scores\n","\n","\n","def replace_two_model_parameters(e_model,t_model,global_sess):\n","  global_sess.run([tf.assign(e,t) for e,t in zip(e_model.parameters,t_model.parameters)])\n","\n","def get_FL(increased_user_number,increased_user_status=True):\n","  tf.reset_default_graph()\n","  tf.set_random_seed(2)\n","  global_sess=tf.Session()\n","  with tf.variable_scope(\"global_model\"):\n","    global_model=FL(\"global_model\",global_sess)\n","  all_user_FL=[]\n","  for i in range(good_user_number):\n","    name=\"u\"+str(i)\n","    with tf.variable_scope(name):\n","      data=all_user_data[i]\n","      label=all_user_label[i]\n","      all_user_FL.append(FL(name,global_sess,data,label,isCommittee=True))\n","\n","  if(increased_user_status):\n","    for i in range(increased_user_number):\n","      name=\"u\"+str(i+good_user_number)\n","      data=datas[(good_user_number+i)*4000:(good_user_number+i+1)*4000]\n","      label=labels[(good_user_number+i)*4000:(good_user_number+i+1)*4000]\n","      with tf.variable_scope(name):\n","        all_user_FL.append(FL(name,global_sess,data,label,isCommittee=True,isBad=False))\n","  else:\n","    for i in range(increased_user_number):\n","      name=\"bad_u\"+str(i)\n","      with tf.variable_scope(name):\n","        all_user_FL.append(FL(name,global_sess,isCommittee=True,isBad=True)) \n","\n","  global_sess.run(tf.global_variables_initializer())\n","  return [global_sess,all_user_FL,global_model]\n","\n","\n","def iterate(global_sess,all_user_FL,global_model):\n","  global_model_score=get_global_model_score(all_user_FL,global_model,global_sess)\n","  broadcast(all_user_FL,global_model,global_sess)\n","  local_train(all_user_FL,global_sess)\n","  all_user_FL_scores=get_all_user_FL_scores(all_user_FL,global_sess)\n","  user_committee_status=get_next_global_model_and_commmittee_users(all_user_FL,global_model,all_user_FL_scores,global_model_score,global_sess)\n","  return global_model.validate(test_data,test_label),user_committee_status\n","\n","def reset_all_user_FL(FLs):\n","  for user_FL in FLs:\n","    user_FL.isCommittee=True\n","  \n","def plot(x,xlabel,ylabel):\n","  figsize = 11,9\n","  figure, ax = plt.subplots(figsize=figsize)\n","  plt.plot(np.arange(0,len(x)),x,c=\"#2E8B57\",linewidth=1)\n","  plt.ylabel(ylabel,fontsize=15)\n","  plt.xlabel(xlabel,fontsize=15)\n","  plt.grid(linestyle='-.')     \n","  plt.show()\n","\n","color=['#2E8B57','#107ab0','orange','#be6400',\"crimson\"]\n","def plot_comparaed_figure(n,value,label,xlabel,ylabel,name):\n","    figsize = 11,9\n","    figure, ax = plt.subplots(figsize=figsize)\n","    for i in range(n):\n","        plt.plot(np.arange(0,len(value[i])),value[i],c=color[i],label=label[i],linewidth=1)\n","    plt.legend(loc=\"best\",fontsize=18)\n","    plt.ylabel(ylabel,fontsize=15)\n","    plt.xlabel(xlabel,fontsize=15)\n","    plt.grid(linestyle='-.')     \n","    plt.show()\n","\n","max_episode=800  \n","max_iteration_number=30\n","\n","def run(RL,module,max_episode=800):\n","    global_sess=tf.Session()\n","    total_reward=[]\n","    train_step=0\n","    t_ec_list=[]\n","    for i in range(max_episode):\n","      random.seed(0)     \n","      state=reseted_state  \n","      _reward_of_everyFL_list=[]\n","\n","      # with graph_drl.as_default():\n","      #   print(sess.run(RL.w3)[2])   \n","      for j in range(max_iteration_number):\n","        action,action_index=RL.choose_action(state)\n","        state_pre,reward,t_ec=move(state,action,module)\n","        user_committee_status=user_committee_status_list[j]\n","        state_=np.concatenate((state_pre,np.array(user_committee_status)))\n","        _reward_of_everyFL_list.append(reward)  \n","        t_ec_list.append(t_ec)\n","\n","        RL.store_transition(state,action_index,reward,state_)\n","\n","        # if i>770:\n","        #   print(action[-2])\n","\n","        state=state_\n","        train_step+=1\n","        if train_step>=RL.memory_size:\n","          RL.learn()\n","        # print(\"train_step: \"+str(train_step)+\"   reward: \"+str(reward))\n","      \n","      # plot(_reward_of_everyFL_list,\"no_\"+str(i)+\"_fl\",\"reward\")\n","      total_reward.append(np.sum(_reward_of_everyFL_list))\n","      if (i+1)%400==0:\n","        plot(total_reward,\"no_\"+str(i)+\"_rl\",\"Total Reward\")\n","        t_ec_array=np.reshape(t_ec_list,[-1,30])\n","        plot(np.mean(t_ec_array,1),\"Episode\",\"Average Energy Consumption\")\n","\n","    return total_reward,t_ec_array\n","\n","# ----------------------------------------------------------------------------\n","# ------------------------------------loss and fix some var------------------\n","# ----------------------------------------------------------------------------\n","\n","\n","# 增加0个用户，module=0,time_limit=超级大\n","\n","increased_user_number=0\n","increased_user_status=True\n","\n","user_committee_status_list=[]\n","\n","# FL_list=get_FL(increased_user_number,increased_user_status)\n","# print(\"accuracy of pre_train: \"+str(FL_list[2].validate(test_data,test_label))) \n","# for j in range(max_iteration_number):\n","#     accuracy,user_committee_status=iterate(FL_list[0],FL_list[1],FL_list[2])\n","#     user_committee_status_list.append(user_committee_status)\n","#     print(accuracy)\n","\n","# tf.reset_default_graph()\n","# FL_list[0].close()\n","\n","import pandas as pd\n","# pd.DataFrame(user_committee_status_list).to_csv(\"/content/drive/MyDrive/EE_blockchain/resource_allocation/user_committee_status_list_0.csv\")\n","user_committee_status_list=pd.read_csv(\"/content/drive/MyDrive/EE_blockchain/resource_allocation/user_committee_status_list_0.csv\",index_col=0).values\n","# user_committee_status_list[user_committee_status_list==0]=1\n","\n","print(user_committee_status_list)\n","\n","user_number=good_user_number+increased_user_number\n","n_features,n_actions,state,actionRangeMatrix=reset(user_number)\n","reseted_state=state.copy()\n","\n","user_isGood=np.array([1 for i in range(good_user_number)])\n","if increased_user_status:\n","  user_isGood=np.concatenate((user_isGood,[1 for i in range(increased_user_number)]))\n","else:\n","  user_isGood=np.concatenate((user_isGood,[0 for i in range(increased_user_number)]))\n","\n","\n","graph_drl=tf.Graph()\n","sess=tf.Session(graph=graph_drl)\n","\n","with graph_drl.as_default():\n","  with tf.variable_scope(\"DDQN\"):\n","    RL_0=DDQN(n_actions,n_features,learning_rate=0.0001,reward_decay=0.8,e_greedy=0.95,replace_target_iter=400,\n","            memory_size=3000,batch_size=32,e_greedy_increment=0.0001,dueling=True,sess=sess\n","    )\n","  tf.set_random_seed(0)\n","  sess.run(tf.global_variables_initializer())\n","\n","np.random.seed(0)\n","total_reward_0,total_ec_array_0=run(RL_0,0,3000)  \n","loss_0=RL_0.cost_his\n","\n","\n","graph_drl.as_default()\n","sess.close()\n","\n","# -------------------------------------改变learning rate--------------------------------\n","different_learning_rate=[0.01,0.001,0.00001,0.000001]\n","reward_with_different_lr=[]\n","reward_with_different_lr.append(total_reward_0)\n","for lr in different_learning_rate:\n","  tf.reset_default_graph()\n","\n","  graph_drl=tf.Graph()\n","  sess=tf.Session(graph=graph_drl)\n","\n","  with graph_drl.as_default():\n","    with tf.variable_scope(\"DDQN\"):\n","      RL_0=DDQN(n_actions,n_features,learning_rate=lr,reward_decay=0.8,e_greedy=0.95,replace_target_iter=400,\n","              memory_size=3000,batch_size=32,e_greedy_increment=0.0001,dueling=True,sess=sess\n","      )\n","    tf.set_random_seed(0)\n","    sess.run(tf.global_variables_initializer())\n","\n","  np.random.seed(0)\n","  total_reward_1r,_=run(RL_0,0,3000)  \n","\n","  graph_drl.as_default()\n","  sess.close()\n","  reward_with_different_lr.append(total_reward_1r)\n","\n","plot_comparaed_figure(5,reward_with_different_lr,[\"Learning rate = 0.0001\",\"Learning rate = 0.01\",\"Learning rate = 0.001\",\"Learning rate = 0.00001\",\"Learning rate = 0.000001\"],\"Episode\",\"Total Reward\",\"oo\")\n","pd.DataFrame(reward_with_different_lr).to_csv(\"/content/drive/MyDrive/EE_blockchain/resource_allocation/reward_with_different_lr.csv\")\n","\n","# -------------------------------------改变module--------------------------------\n","reward_with_different_module=[]\n","average_energy_consumption_with_different_module=[]\n","reward_with_different_module.append(total_reward_0[:800])\n","average_energy_consumption_with_different_module.append(np.mean(total_ec_array_0[0:800,:],1))\n","\n","for i in range(1,4):\n","  tf.reset_default_graph()\n","\n","  graph_drl=tf.Graph()\n","  sess=tf.Session(graph=graph_drl)\n","\n","  with graph_drl.as_default():\n","    with tf.variable_scope(\"DDQN\"):\n","      RL_0=DDQN(n_actions,n_features,learning_rate=0.0001,reward_decay=0.8,e_greedy=0.95,replace_target_iter=400,\n","              memory_size=3000,batch_size=32,e_greedy_increment=0.0001,dueling=True,sess=sess\n","      )\n","    tf.set_random_seed(0)\n","    sess.run(tf.global_variables_initializer())\n","\n","  np.random.seed(0)\n","  total_reward_module,total_ec_array_module=run(RL_0,i)  \n","  reward_with_different_module.append(total_reward_module)\n","  average_energy_consumption_with_different_module.append(np.mean(total_ec_array_module,1))\n","  graph_drl.as_default()\n","  sess.close()\n","\n","plot(loss_0[:6000],\"Training steps\",\"loss\")\n","plot_comparaed_figure(4,reward_with_different_module,[\"Proposed_scheme\",\"Proposed_scheme_with_fixed_channel_allocation\",\"Proposed_scheme_with_fixed_blocksize\",\"Proposed_scheme_with_fixed_block_producer\"],\"Episode\",\"Total Reward\",\"oo\")\n","plot_comparaed_figure(4,average_energy_consumption_with_different_module,[\"Proposed_scheme\",\"Proposed_scheme_with_fixed_channel_allocation\",\"Proposed_scheme_with_fixed_blocksize\",\"Proposed_scheme_with_fixed_block_producer\"],\"Episode\",\"Average Energy Consumption\",\"oo\")\n","pd.DataFrame(loss_0).to_csv(\"/content/drive/MyDrive/EE_blockchain/resource_allocation/loss.csv\")\n","pd.DataFrame(reward_with_different_module).to_csv(\"/content/drive/MyDrive/EE_blockchain/resource_allocation/reward_with_different_module.csv\")\n","pd.DataFrame(average_energy_consumption_with_different_module).to_csv(\"/content/drive/MyDrive/EE_blockchain/resource_allocation/average_energy_consumption_with_different_module.csv\")"],"execution_count":null,"outputs":[]}]}